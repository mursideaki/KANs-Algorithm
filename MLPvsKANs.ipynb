{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Kolmogorov-Arnold Ağları (KAN’lar): Derin Öğrenmeye Yeni Bir Bakış**\n",
        "\n",
        "Son zamanlarda, derin öğrenme alanında dikkat çeken bir makale yayımlandı: Kolmogorov-Arnold Ağları (KAN’lar). Bu yeni yayın, derin öğrenme dünyasında büyük bir yenilik olarak görülüyor. Peki, Kolmogorov-Arnold Ağları nedir ve bu yeni yöntem, geleneksel yöntemlerden ne gibi farklılıklar sunuyor?\n",
        "\n",
        "##KAN’lar: Yeni Bir Alternatif\n",
        "\n",
        "Geleneksel olarak, çok katmanlı algılayıcılar (MLP’ler), derin öğrenme modellerinin temel yapı taşlarından biridir. Bu ağlar, giriş verileri ile çıktı arasındaki karmaşık ilişkileri modelleyebilme yeteneğiyle tanınır. Ancak, MLP’ler bazı sınırlamalara sahiptir. Örneğin, MLP’lerde aktivasyon fonksiyonları sabittir ve bu fonksiyonlar, her düğümde aynı işlemi gerçekleştirir. Bu durum, modelin yorumlanabilirliğini zorlaştırabilir ve verinin anlamını daha iyi açıklamak için ek analiz araçlarına ihtiyaç duyulmasına neden olabilir.\n",
        "\n",
        "KAN’lar, bu durumu tersine çevirerek her kenara öğrenilebilir aktivasyon fonksiyonları yerleştirir. Bu, her ağırlık parametresinin öğrenilebilir bir 1D fonksiyonla değiştirilmesi anlamına gelir. KAN’lar, MLP’lerden daha küçük hesaplama grafiklerine sahip olabilen esnek bir yapıya sahiptir. Ayrıca, bazen daha büyük bir MLP’den çok daha iyi performans sergileyebilirler.\n",
        "\n",
        "Bir örnek vermek gerekirse, Kolmogorov-Arnold Ağları, doğrusal olmayan diferansiyel denklemleri (PDE) çözme konusunda, 2 katmanlı ve 10 genişlikli bir KAN, 4 katmanlı ve 100 genişlikli bir MLP'ye göre 100 kat daha hassas ve 100 kat daha parametre verimli olabilir.\n",
        "\n",
        "##Kolmogorov-Arnold Teoremi ve KAN’lar\n",
        "\n",
        "KAN’lar, Kolmogorov-Arnold Temsil Teoremi’ne dayanmaktadır. Bu teorem, çok değişkenli sürekli bir fonksiyonun, tek değişkenli fonksiyonların bir bileşimi ve toplama işlemiyle ifade edilebileceğini söyler. Bu teorem sayesinde, çok değişkenli denklemler daha basit parçalara ayrılabilir. Bu, makine öğrenimi alanında oldukça önemli bir adım olarak kabul edilebilir çünkü çok değişkenli fonksiyonları çözme zorluğu, aslında tek değişkenli fonksiyonları öğrenmeye indirgenebilir.\n",
        "\n",
        "##KAN’ların Temel Yapısı\n",
        "\n",
        "KAN’lar, her bir kenar için öğrenilebilir aktivasyon fonksiyonlarına dayanır. MLP’lerde ise her düğümde sabit aktivasyon fonksiyonları kullanılır. KAN’lar, daha az parametre ile daha güçlü modelleme yapabilme kapasitesine sahiptir. Aktivasyon fonksiyonları, genellikle B-splineler gibi polinom eğrilerinden oluşur. Bu eğriler, yalnızca yakın çevresindeki kontrol noktalarından etkilenir, böylece modelin stabilitesini ve diferansiyasyon yeteneğini artırır.\n",
        "\n",
        "##KAN’ların Avantajları\n",
        "\n",
        "KAN’lar, sabit aktivasyon fonksiyonlarına sahip MLP’lere göre birçok avantaja sahiptir:\n",
        "\n",
        "**Daha Fazla Esneklik:** KAN’lar, kenarlardaki öğrenilebilir aktivasyon fonksiyonları sayesinde daha esnektir.\n",
        "\n",
        "**Daha Az Parametre ile Daha İyi Performans:** KAN’lar, daha az parametre ile daha iyi performans gösterebilir. Özellikle karmaşık denklemleri çözme konusunda oldukça etkilidirler.\n",
        "\n",
        "**Katastrofik Unutma Sorununu Azaltma:** B-splineler, yerel kontrol sağlar, böylece modelin daha önce öğrendiği bilgileri unutma olasılığı daha düşüktür.\n",
        "\n",
        "##Eğitim Süreci ve Zorluklar\n",
        "\n",
        "KAN’ların eğitimi, geleneksel derin öğrenme ağlarına benzer şekilde yapılır. Geri yayılım algoritması kullanılarak ağırlıklar ve aktivasyon fonksiyonları güncellenir. Ancak, KAN’ların eğitim süreci, MLP’lere kıyasla yaklaşık 10 kat daha yavaş olabilir. Yine de, performans ve model yorumlanabilirliği açısından KAN’lar, bazı durumlarda MLP’lerden daha avantajlıdır.\n",
        "\n",
        "##KAN’lar mı, MLP’ler mi?\n",
        "\n",
        "KAN’ların en büyük dezavantajı, eğitim hızının MLP’lere kıyasla çok daha düşük olmasıdır. Ancak, araştırmalar henüz KAN’ların verimliliğini optimize etmek üzerine yoğunlaşmamıştır. Eğer hızlı eğitim gerekiyorsa, MLP’ler tercih edilebilir. Ancak, modelin doğruluğu ve yorumlanabilirliği ön planda ise, KAN’lar ciddi bir alternatif olarak değerlendirilebilir.\n",
        "\n",
        "##Sonuç\n",
        "\n",
        "KAN’lar, derin öğrenme dünyasında yeni bir soluk getiren bir yöntem olarak karşımıza çıkıyor. MLP’lere kıyasla daha esnek ve parametrik açıdan verimli olabilen KAN’lar, özellikle çok değişkenli fonksiyonları çözme konusunda oldukça başarılıdır. Yavaş eğitim süresi gibi bazı zorlukları olsa da, gelecekte KAN’ların verimliliği artırıldığında, derin öğrenme alanında önemli bir yer edinebilirler.\n",
        "\n",
        "KAN’lar ve MLP’ler arasındaki farkları ve her iki yapının avantajlarını daha derinlemesine keşfetmek için daha fazla araştırma yapılması gerektiği aşikardır. Şu anda, KAN’lar, doğruluk ve açıklanabilirlik isteyenler için umut verici bir seçenek olarak dikkat çekiyor."
      ],
      "metadata": {
        "id": "53b9SMODugOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/KindXiaoming/pykan.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni96W1ktyD1T",
        "outputId": "e97b65fe-c57d-4632-8143-764ca4a68efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/KindXiaoming/pykan.git\n",
            "  Cloning https://github.com/KindXiaoming/pykan.git to /tmp/pip-req-build-b50q0q72\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/KindXiaoming/pykan.git /tmp/pip-req-build-b50q0q72\n",
            "  Resolved https://github.com/KindXiaoming/pykan.git to commit f871c26d4df788ec1ba309c2c9c1803d82606b06\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pykan\n",
            "  Building wheel for pykan (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykan: filename=pykan-0.2.8-py3-none-any.whl size=78208 sha256=b7b9de52b5ac691761ae2c93f8be2bb12831e7d082a6574764013cf0c1d416b3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4a5sg0pm/wheels/47/ca/5a/98124e020f3119f51c17f78738c621c140b7aa803b0feda76e\n",
            "Successfully built pykan\n",
            "Installing collected packages: pykan\n",
            "Successfully installed pykan-0.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9pLCj8gx-bm",
        "outputId": "991b4586-f3f2-41a2-bda6-4a291ffe6d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boston Housing veri seti başarıyla yüklendi ve işlendi!\n",
            "Epoch [10/50], Loss: 331.5022\n",
            "Epoch [20/50], Loss: 353.0611\n",
            "Epoch [30/50], Loss: 144.3524\n",
            "Epoch [40/50], Loss: 125.3957\n",
            "Epoch [50/50], Loss: 94.1530\n",
            "MLP Modeli Eğitim Süresi: 0.06 saniye\n",
            "MLP Test Loss: 86.0081\n",
            "checkpoint directory created: ./model\n",
            "saving model version 0.0\n",
            "Epoch [10/50], Loss (KAN): 3781.4514\n",
            "Epoch [20/50], Loss (KAN): 518.2750\n",
            "Epoch [30/50], Loss (KAN): 156.1805\n",
            "Epoch [40/50], Loss (KAN): 249.3647\n",
            "Epoch [50/50], Loss (KAN): 132.1996\n",
            "KAN Modeli Eğitim Süresi: 33.67 saniye\n",
            "KAN Test Loss: 128.8548\n",
            "\n",
            "Model Karşılaştırması:\n",
            "MLP Test Loss: 86.0081, Eğitim Süresi: 0.06 saniye\n",
            "KAN Test Loss: 128.8548, Eğitim Süresi: 33.67 saniye\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Veri setini URL'den indir\n",
        "url = \"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\"\n",
        "boston = pd.read_csv(url)\n",
        "\n",
        "# Özellikler ve hedef değişkeni ayır\n",
        "X = boston.drop(columns=[\"medv\"])  # 'medv' hedef sütunu\n",
        "y = boston[\"medv\"]\n",
        "\n",
        "# Veriyi eğitim ve test olarak ayır\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tensorlara dönüştür\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "print(\"Boston Housing veri seti başarıyla yüklendi ve işlendi!\")\n",
        "\n",
        "# Aygıt Seçimi\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# MLP Modeli Tanımlama\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "mlp_model = MLP(input_dim=X.shape[1], hidden_dim=64, output_dim=1).to(device)\n",
        "\n",
        "# Kayıp Fonksiyonu ve Optimizasyon\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n",
        "\n",
        "# Eğitim Döngüsü\n",
        "start_time = time.time()\n",
        "\n",
        "mlp_model.train()\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = mlp_model(X_train_tensor.to(device))\n",
        "    loss = criterion(outputs, y_train_tensor.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/50], Loss: {loss.item():.4f}\")\n",
        "\n",
        "mlp_training_time = time.time() - start_time\n",
        "print(f\"MLP Modeli Eğitim Süresi: {mlp_training_time:.2f} saniye\")\n",
        "\n",
        "# Test Sonuçları\n",
        "mlp_model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = mlp_model(X_test_tensor.to(device))\n",
        "    test_loss = criterion(predictions, y_test_tensor.to(device))\n",
        "    print(f\"MLP Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "# KAN Modeli Tanımlama\n",
        "from kan import KAN\n",
        "\n",
        "kan_model = KAN(width=[X.shape[1], 64, 1], grid=5, k=3, seed=42, device=device).to(device)\n",
        "criterion_kan = nn.MSELoss()\n",
        "optimizer_kan = optim.Adam(kan_model.parameters(), lr=0.001)\n",
        "\n",
        "# KAN Eğitim Döngüsü\n",
        "start_time = time.time()\n",
        "\n",
        "# KAN Eğitim Döngüsü\n",
        "kan_model.train()\n",
        "for epoch in range(50):\n",
        "    optimizer_kan.zero_grad()\n",
        "    outputs_kan = kan_model(torch.tensor(X_train.values, dtype=torch.float32).to(device))  # .values eklendi\n",
        "    loss_kan = criterion_kan(outputs_kan, torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device))  # .values eklendi\n",
        "    loss_kan.backward()\n",
        "    optimizer_kan.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/50], Loss (KAN): {loss_kan.item():.4f}\")\n",
        "\n",
        "kan_training_time = time.time() - start_time\n",
        "print(f\"KAN Modeli Eğitim Süresi: {kan_training_time:.2f} saniye\")\n",
        "\n",
        "# Test Sonuçları\n",
        "kan_model.eval()\n",
        "with torch.no_grad():\n",
        "    # X_test ve y_test'in Pandas DataFrame olduğunu varsayıyoruz. Bunları NumPy dizilerine dönüştürüyoruz\n",
        "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)  # X_test'i NumPy'ye çeviriyoruz\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)  # y_test'i NumPy'ye çeviriyoruz\n",
        "\n",
        "    predictions_kan = kan_model(X_test_tensor)\n",
        "    test_loss_kan = criterion_kan(predictions_kan, y_test_tensor)\n",
        "    print(f\"KAN Test Loss: {test_loss_kan.item():.4f}\")\n",
        "\n",
        "# Sonuçları Karşılaştır\n",
        "print(\"\\nModel Karşılaştırması:\")\n",
        "print(f\"MLP Test Loss: {test_loss.item():.4f}, Eğitim Süresi: {mlp_training_time:.2f} saniye\")\n",
        "print(f\"KAN Test Loss: {test_loss_kan.item():.4f}, Eğitim Süresi: {kan_training_time:.2f} saniye\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modellerimizin ilk eğitimi yukarıda gördüğümüz gibi sonuçlandı MLP hem çok hızlı hem de daha başarılı görünüyor. KAN'ın parametrelerinde değişiklik yaparak bakalım sonuçlarda farklılık yaratabilir miyiz ve süre ne kadar artar?\n",
        "\n",
        "Parametreler nedir bir bakalım:\n",
        "\n",
        "width=[X.shape[1], 64, 1]: Bu liste, ağın katman genişliklerini belirtir. X.shape[1], giriş verisinin boyutunu temsil eder. 64 ve 1 ise ara katmanların nöron sayılarını belirtir.\n",
        "\n",
        "grid=5: Bu parametre, KAN'ın grid boyutunu belirtir. Grid boyutu, modelin karmaşıklığına ve öğrenme kapasitesine doğrudan etkide bulunur. Daha büyük bir grid, modelin daha karmaşık fonksiyonları yakalamasına olanak tanır.\n",
        "\n",
        "k=3: Bu parametre, her bir grid hücresindeki komşu sayısını belirtir. Daha büyük bir k değeri, modelin daha fazla yerel bilgiyi kullanmasına neden olur.\n",
        "\n",
        "seed=42: Bu parametre, rastgele sayı üretecinin başlangıç değerini belirler. Bu sayede deneyler tekrarlanabilir hale gelir.\n",
        "\n",
        "device=device: Modelin hangi cihazda (CPU veya GPU) çalışacağını belirtir.\n",
        "\n",
        "Denemek için ilk olarak grid parametresini 5 'ten 7'ye çıkararak deniyoruz.\n",
        "\n",
        "Son olarak learning rate de değiştirilebilir ama modeller arasındaki farkı net olarak göstermek istiyorsak MLP için de değiştirmemiz uygun olur. Şu anda sadece KAN ne kadar başarılı onu görmek istediğim için lr değerinden önce KAN'a ait parametreleri değiştirerek deneyeceğim."
      ],
      "metadata": {
        "id": "iwqJCLPkvz0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# MLP Modeli Tanımlama\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "mlp_model = MLP(input_dim=X.shape[1], hidden_dim=64, output_dim=1).to(device)\n",
        "\n",
        "# Kayıp Fonksiyonu ve Optimizasyon\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n",
        "\n",
        "# Eğitim Döngüsü\n",
        "start_time = time.time()\n",
        "\n",
        "mlp_model.train()\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = mlp_model(X_train_tensor.to(device))\n",
        "    loss = criterion(outputs, y_train_tensor.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/50], Loss: {loss.item():.4f}\")\n",
        "\n",
        "mlp_training_time = time.time() - start_time\n",
        "print(f\"MLP Modeli Eğitim Süresi: {mlp_training_time:.2f} saniye\")\n",
        "\n",
        "# Test Sonuçları\n",
        "mlp_model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = mlp_model(X_test_tensor.to(device))\n",
        "    test_loss = criterion(predictions, y_test_tensor.to(device))\n",
        "    print(f\"MLP Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "# KAN Modeli Tanımlama\n",
        "from kan import KAN\n",
        "\n",
        "kan_model = KAN(width=[X.shape[1], 64, 1], grid=7, k=3, seed=42, device=device).to(device)\n",
        "criterion_kan = nn.MSELoss()\n",
        "optimizer_kan = optim.Adam(kan_model.parameters(), lr=0.001)\n",
        "\n",
        "# KAN Eğitim Döngüsü\n",
        "start_time = time.time()\n",
        "\n",
        "# KAN Eğitim Döngüsü\n",
        "kan_model.train()\n",
        "for epoch in range(50):\n",
        "    optimizer_kan.zero_grad()\n",
        "    outputs_kan = kan_model(torch.tensor(X_train.values, dtype=torch.float32).to(device))  # .values eklendi\n",
        "    loss_kan = criterion_kan(outputs_kan, torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device))  # .values eklendi\n",
        "    loss_kan.backward()\n",
        "    optimizer_kan.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/50], Loss (KAN): {loss_kan.item():.4f}\")\n",
        "\n",
        "kan_training_time = time.time() - start_time\n",
        "print(f\"KAN Modeli Eğitim Süresi: {kan_training_time:.2f} saniye\")\n",
        "\n",
        "# Test Sonuçları\n",
        "kan_model.eval()\n",
        "with torch.no_grad():\n",
        "    # X_test ve y_test'in Pandas DataFrame olduğunu varsayıyoruz. Bunları NumPy dizilerine dönüştürüyoruz\n",
        "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)  # X_test'i NumPy'ye çeviriyoruz\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)  # y_test'i NumPy'ye çeviriyoruz\n",
        "\n",
        "    predictions_kan = kan_model(X_test_tensor)\n",
        "    test_loss_kan = criterion_kan(predictions_kan, y_test_tensor)\n",
        "    print(f\"KAN Test Loss: {test_loss_kan.item():.4f}\")\n",
        "\n",
        "# Sonuçları Karşılaştır\n",
        "print(\"\\nModel Karşılaştırması:\")\n",
        "print(f\"MLP Test Loss: {test_loss.item():.4f}, Eğitim Süresi: {mlp_training_time:.2f} saniye\")\n",
        "print(f\"KAN Test Loss: {test_loss_kan.item():.4f}, Eğitim Süresi: {kan_training_time:.2f} saniye\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty68xgSm4j37",
        "outputId": "2efcff87-f032-45f0-b0c5-79323a058a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 331.5022\n",
            "Epoch [20/50], Loss: 353.0611\n",
            "Epoch [30/50], Loss: 144.3524\n",
            "Epoch [40/50], Loss: 125.3957\n",
            "Epoch [50/50], Loss: 94.1530\n",
            "MLP Modeli Eğitim Süresi: 0.07 saniye\n",
            "MLP Test Loss: 86.0081\n",
            "checkpoint directory created: ./model\n",
            "saving model version 0.0\n",
            "Epoch [10/50], Loss (KAN): 137.9728\n",
            "Epoch [20/50], Loss (KAN): 89.3437\n",
            "Epoch [30/50], Loss (KAN): 98.2949\n",
            "Epoch [40/50], Loss (KAN): 75.6463\n",
            "Epoch [50/50], Loss (KAN): 69.7183\n",
            "KAN Modeli Eğitim Süresi: 33.78 saniye\n",
            "KAN Test Loss: 44.7019\n",
            "\n",
            "Model Karşılaştırması:\n",
            "MLP Test Loss: 86.0081, Eğitim Süresi: 0.07 saniye\n",
            "KAN Test Loss: 44.7019, Eğitim Süresi: 33.78 saniye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sadece grid değerini 5'ten 7'ye çıkardığımızda eğitim süresinde büyük bir fark gözlenmeksizin başarımızın oldukça iyi düzeye geldiğini görüyoruz. Peki bu loss değerleri neyi ifade ediyor?\n",
        "\n",
        "Loss değerimizi regresyon problemlerinde sıkça kullanılan MSE (Mean Squared Error) ortalama kare hata ile hesaplıyoruz yani hata değerinin karesini alarak sonucu buluyoruz. Neden karesini alıyoruz?\n",
        "\n",
        "Kare Almanın Nedeni: Hata değerlerinin kare alınmasının nedeni, negatif ve pozitif hataların eşit şekilde cezalandırılması ve büyük hataların daha fazla ağırlıklandırılması olarak açıklanabilir.\n",
        "\n",
        "Loss değerimizin bu dataset için ev fiyatlarında yapılan tahminin ortalama sapması olarak düşünebiliriz yani daha düşük loss değeri daha başarılı bir modeli işaret edecektir. Test setimizden ilk üç değeri alıp MLP ve KAN modellerimizin tahminlerini karşılaştıralım."
      ],
      "metadata": {
        "id": "OKuqXodxzbkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test verisi örnek (örnek 3 fiyat)\n",
        "X_test_sample = torch.tensor(X_test.values[:3], dtype=torch.float32).to(device)\n",
        "y_test_sample = torch.tensor(y_test.values[:3], dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "# MLP tahminleri\n",
        "mlp_model.eval()\n",
        "with torch.no_grad():\n",
        "    mlp_predictions = mlp_model(X_test_sample).cpu().numpy()\n",
        "\n",
        "# KAN tahminleri\n",
        "kan_model.eval()\n",
        "with torch.no_grad():\n",
        "    kan_predictions = kan_model(X_test_sample).cpu().numpy()\n",
        "\n",
        "# Gerçek fiyatlar (test veri setindeki ilk 3 fiyat)\n",
        "real_prices = y_test_sample.cpu().numpy()\n",
        "\n",
        "# Fiyatları ve tahminleri yazdırma\n",
        "print(\"Gerçek Fiyatlar (USD): \", real_prices.flatten())\n",
        "print(\"MLP Tahminleri (USD): \", mlp_predictions.flatten())\n",
        "print(\"KAN Tahminleri (USD): \", kan_predictions.flatten())\n",
        "\n",
        "# Farkları hesaplama\n",
        "mlp_differences = np.abs(real_prices.flatten() - mlp_predictions.flatten())\n",
        "kan_differences = np.abs(real_prices.flatten() - kan_predictions.flatten())\n",
        "\n",
        "print(\"\\nMLP Fiyat Hataları (USD): \", mlp_differences)\n",
        "print(\"KAN Fiyat Hataları (USD): \", kan_differences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjFpbsoF7U-f",
        "outputId": "80e82471-9c42-49b7-acd7-0afd85ad5b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gerçek Fiyatlar (USD):  [23.6 32.4 13.6]\n",
            "MLP Tahminleri (USD):  [23.97135  23.747486 27.646864]\n",
            "KAN Tahminleri (USD):  [23.439716 28.14038  17.155827]\n",
            "\n",
            "MLP Fiyat Hataları (USD):  [ 0.37134933  8.652515   14.046864  ]\n",
            "KAN Fiyat Hataları (USD):  [0.16028404 4.2596207  3.5558262 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukarıdaki değerlerden de görüyoruz ki ilk örneğimiz için her iki model de oldukça başarılı sonuç vermişken ikinci örneğimizde KAN 4.25k dolar hata verdi MLP'nin hatası 8.65k dolar oldu, üçüncü örnek içinse KAN 3.55k dolar sapma gösterirken MLP 14k dolar civarında bir sapma göstermiş oldu.\n",
        "\n",
        "Şimdi k değerimizi değiştirelim."
      ],
      "metadata": {
        "id": "hJ9mY3pf0YWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Modeli Tanımlama\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "mlp_model = MLP(input_dim=X.shape[1], hidden_dim=64, output_dim=1).to(device)\n",
        "\n",
        "# Kayıp Fonksiyonu ve Optimizasyon\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n",
        "\n",
        "# Eğitim Döngüsü\n",
        "start_time = time.time()\n",
        "\n",
        "mlp_model.train()\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = mlp_model(X_train_tensor.to(device))\n",
        "    loss = criterion(outputs, y_train_tensor.to(device))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/50], Loss: {loss.item():.4f}\")\n",
        "\n",
        "mlp_training_time = time.time() - start_time\n",
        "print(f\"MLP Modeli Eğitim Süresi: {mlp_training_time:.2f} saniye\")\n",
        "\n",
        "# Test Sonuçları\n",
        "mlp_model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = mlp_model(X_test_tensor.to(device))\n",
        "    test_loss = criterion(predictions, y_test_tensor.to(device))\n",
        "    print(f\"MLP Test Loss: {test_loss.item():.4f}\")\n",
        "\n",
        "# KAN Modeli Tanımlama\n",
        "from kan import KAN\n",
        "\n",
        "kan_model = KAN(width=[X.shape[1], 64, 1], grid=5, k=7, seed=42, device=device).to(device)\n",
        "criterion_kan = nn.MSELoss()\n",
        "optimizer_kan = optim.Adam(kan_model.parameters(), lr=0.001)\n",
        "\n",
        "# KAN Eğitim Döngüsü\n",
        "start_time = time.time()\n",
        "\n",
        "# KAN Eğitim Döngüsü\n",
        "kan_model.train()\n",
        "for epoch in range(50):\n",
        "    optimizer_kan.zero_grad()\n",
        "    outputs_kan = kan_model(torch.tensor(X_train.values, dtype=torch.float32).to(device))  # .values eklendi\n",
        "    loss_kan = criterion_kan(outputs_kan, torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device))  # .values eklendi\n",
        "    loss_kan.backward()\n",
        "    optimizer_kan.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch + 1}/50], Loss (KAN): {loss_kan.item():.4f}\")\n",
        "\n",
        "kan_training_time = time.time() - start_time\n",
        "print(f\"KAN Modeli Eğitim Süresi: {kan_training_time:.2f} saniye\")\n",
        "\n",
        "# Test Sonuçları\n",
        "kan_model.eval()\n",
        "with torch.no_grad():\n",
        "    # X_test ve y_test'in Pandas DataFrame olduğunu varsayıyoruz. Bunları NumPy dizilerine dönüştürüyoruz\n",
        "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)  # X_test'i NumPy'ye çeviriyoruz\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1).to(device)  # y_test'i NumPy'ye çeviriyoruz\n",
        "\n",
        "    predictions_kan = kan_model(X_test_tensor)\n",
        "    test_loss_kan = criterion_kan(predictions_kan, y_test_tensor)\n",
        "    print(f\"KAN Test Loss: {test_loss_kan.item():.4f}\")\n",
        "\n",
        "# Sonuçları Karşılaştır\n",
        "print(\"\\nModel Karşılaştırması:\")\n",
        "print(f\"MLP Test Loss: {test_loss.item():.4f}, Eğitim Süresi: {mlp_training_time:.2f} saniye\")\n",
        "print(f\"KAN Test Loss: {test_loss_kan.item():.4f}, Eğitim Süresi: {kan_training_time:.2f} saniye\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_kZbcyL5GXd",
        "outputId": "b4ffaf30-85fd-4743-a5c7-d152e921e36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 331.5022\n",
            "Epoch [20/50], Loss: 353.0611\n",
            "Epoch [30/50], Loss: 144.3524\n",
            "Epoch [40/50], Loss: 125.3957\n",
            "Epoch [50/50], Loss: 94.1530\n",
            "MLP Modeli Eğitim Süresi: 0.07 saniye\n",
            "MLP Test Loss: 86.0081\n",
            "checkpoint directory created: ./model\n",
            "saving model version 0.0\n",
            "Epoch [10/50], Loss (KAN): 3781.1677\n",
            "Epoch [20/50], Loss (KAN): 518.0831\n",
            "Epoch [30/50], Loss (KAN): 156.2029\n",
            "Epoch [40/50], Loss (KAN): 249.3581\n",
            "Epoch [50/50], Loss (KAN): 132.1538\n",
            "KAN Modeli Eğitim Süresi: 33.78 saniye\n",
            "KAN Test Loss: 128.8053\n",
            "\n",
            "Model Karşılaştırması:\n",
            "MLP Test Loss: 86.0081, Eğitim Süresi: 0.07 saniye\n",
            "KAN Test Loss: 128.8053, Eğitim Süresi: 33.78 saniye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sonuçlardan gördüğümüz gibi k değerinin değiştirilmesi sonuç üzerinde herhangi bir değişiklik yapmadı."
      ],
      "metadata": {
        "id": "KcxjOilL2Tg5"
      }
    }
  ]
}